# Alert Management and Recovery Procedures

## Overview

This document provides comprehensive guidance for managing system alerts generated by the Enhanced Service Monitoring system. It includes alert types, severity classifications, notification channels, and step-by-step recovery procedures.

## Alert Types and Classifications

### Critical Alerts (CRITICAL)

**Trigger Conditions**: Authentication failures that prevent service operation

#### Authentication Failure (401 Unauthorized)

**Alert Type**: `authentication_failure`
**Services**: FOGIS API, Google Drive, Avatar Service, Phonebook Service
**Impact**: Complete service disruption

**Example Alert**:
```
ðŸš¨ FOGIS API Client Alert: authentication_failure - FOGIS API authentication failed
Service: fogis-api-client
Severity: CRITICAL
Error: HTTP 401: Unauthorized access
```

**Recovery Actions**:
1. **Check Environment Variables**
   ```bash
   # Verify FOGIS credentials are set
   echo $FOGIS_USERNAME
   echo $FOGIS_PASSWORD
   echo $FOGIS_API_KEY
   ```

2. **Verify Account Status**
   - Log into FOGIS web interface manually
   - Check if account is locked or suspended
   - Verify subscription status

3. **Test Credentials**
   ```bash
   # Test authentication manually
   curl -u "$FOGIS_USERNAME:$FOGIS_PASSWORD" \
        -H "X-API-Key: $FOGIS_API_KEY" \
        https://api.fogis.com/auth/test
   ```

4. **Update Credentials if Needed**
   ```bash
   # Update environment variables
   export FOGIS_PASSWORD="new_password"
   # Restart services
   docker-compose restart match-list-processor
   ```

**Escalation**: If credentials are correct but authentication still fails, contact FOGIS support immediately.

### High Priority Alerts (HIGH)

**Trigger Conditions**: Service failures and authorization issues

#### Service Unavailable (500/502/503)

**Alert Type**: `service_failure`
**Services**: All external services
**Impact**: Temporary service disruption

**Example Alert**:
```
ðŸš¨ Google Drive Service Alert: service_failure - Google Drive API service unavailable
Service: google-drive-service
Severity: HIGH
Error: HTTP 503: Service Temporarily Unavailable
```

**Recovery Actions**:
1. **Check Service Status**
   - Visit service status pages:
     - FOGIS: https://status.fogis.com
     - Google Drive: https://status.cloud.google.com
     - Check social media for outage reports

2. **Verify Network Connectivity**
   ```bash
   # Test network connectivity
   ping api.fogis.com
   ping www.googleapis.com

   # Test DNS resolution
   nslookup api.fogis.com
   ```

3. **Check Service Logs**
   ```bash
   # View recent service logs
   docker-compose logs --tail=50 match-list-processor
   docker-compose logs --tail=50 fogis-api-client-service
   ```

4. **Implement Temporary Workaround**
   - Enable graceful degradation mode if available
   - Notify users of temporary service limitations
   - Schedule retry operations

**Escalation**: If service remains unavailable for >30 minutes, escalate to infrastructure team.

#### Authorization Failure (403 Forbidden)

**Alert Type**: `authorization_failure`
**Services**: FOGIS API, Google Drive
**Impact**: Access denied to specific resources

**Recovery Actions**:
1. **Check Permissions**
   - Verify account has required permissions
   - Check if API quotas are exceeded
   - Review recent permission changes

2. **Review API Limits**
   ```bash
   # Check Google Drive quota
   curl -H "Authorization: Bearer $GDRIVE_TOKEN" \
        https://www.googleapis.com/drive/v3/about?fields=storageQuota
   ```

3. **Contact Service Provider**
   - Request permission review
   - Check for policy changes
   - Verify account standing

### Medium Priority Alerts (MEDIUM)

**Trigger Conditions**: Network issues and performance degradation

#### Connection Timeout

**Alert Type**: `connection_failure`
**Services**: All external services
**Impact**: Intermittent service disruption

**Recovery Actions**:
1. **Check Network Status**
   ```bash
   # Test connectivity
   traceroute api.fogis.com

   # Check local network
   ping 8.8.8.8
   ```

2. **Adjust Timeout Settings**
   ```bash
   # Temporarily increase timeouts
   export API_TIMEOUT_SECONDS=60
   docker-compose restart match-list-processor
   ```

3. **Monitor Network Performance**
   - Check bandwidth utilization
   - Review network latency
   - Contact ISP if persistent

#### Slow Response Time

**Alert Type**: `slow_response`
**Services**: All external services
**Impact**: Performance degradation

**Recovery Actions**:
1. **Monitor Service Performance**
   ```bash
   # Check response times
   time curl -s https://api.fogis.com/health
   ```

2. **Review System Resources**
   ```bash
   # Check CPU and memory usage
   docker stats

   # Check disk space
   df -h
   ```

3. **Optimize Configuration**
   - Increase connection pool sizes
   - Adjust retry strategies
   - Consider caching mechanisms

#### JSON Parsing Error

**Alert Type**: `parsing_failure`
**Services**: All external services
**Impact**: Data processing issues

**Recovery Actions**:
1. **Examine Response Data**
   ```bash
   # Capture raw response
   curl -v https://api.fogis.com/matches > response.json

   # Validate JSON
   python -m json.tool response.json
   ```

2. **Check API Version Compatibility**
   - Review API documentation for changes
   - Verify request headers and parameters
   - Update parsing logic if needed

3. **Implement Fallback Handling**
   - Add additional error handling
   - Implement data validation
   - Log detailed error information

## Notification Channels

### Email Notifications

**Configuration**: Configured via stakeholder management system
**Recipients**: Administrators, system operators
**Delivery Time**: <60 seconds for critical alerts

**Email Format**:
```
Subject: ðŸš¨ CRITICAL: FOGIS API Authentication Failure

Service: fogis-api-client
Alert Type: authentication_failure
Severity: CRITICAL
Timestamp: 2025-09-02T17:30:00Z

Error Details:
HTTP 401: Unauthorized access

Recovery Actions:
1. Check FOGIS credentials in environment variables
2. Verify FOGIS account status
3. Contact FOGIS support if credentials are correct

Affected Functionality:
- Match processing suspended
- Change detection unavailable
- Notifications may be delayed

System: Match List Processor v2.0.0
```

### Discord Webhooks

**Configuration**: Set via `DISCORD_WEBHOOK_URL` environment variable
**Recipients**: Development team, operations channel
**Delivery Time**: <30 seconds for all alerts

**Discord Format**:
```json
{
  "embeds": [{
    "title": "ðŸš¨ System Alert: Authentication Failure",
    "description": "FOGIS API authentication failed",
    "color": 15158332,
    "fields": [
      {"name": "Service", "value": "fogis-api-client", "inline": true},
      {"name": "Severity", "value": "CRITICAL", "inline": true},
      {"name": "Alert Type", "value": "authentication_failure", "inline": true}
    ],
    "timestamp": "2025-09-02T17:30:00Z"
  }]
}
```

### Generic Webhooks

**Configuration**: Configurable webhook endpoints for external integrations
**Use Cases**: PagerDuty, Slack, custom monitoring systems
**Delivery Time**: <90 seconds for all alerts

## Alert Deduplication

### Cooldown Mechanism

**Purpose**: Prevent notification spam from repeated failures
**Duration**: 5 minutes (300 seconds) between duplicate alerts
**Scope**: Per service and alert type combination

**Implementation**:
```python
# Alert cooldown logic
alert_key = f"{service}:{alert_type}"
last_alert_time = self._last_alert_times.get(alert_key, 0)
current_time = time.time()

if current_time - last_alert_time < self._alert_cooldown:
    # Skip duplicate alert
    return

self._last_alert_times[alert_key] = current_time
```

### Smart Aggregation

**Burst Protection**: Multiple rapid failures trigger single aggregated alert
**Escalation**: Persistent issues trigger escalated notifications
**Recovery Notifications**: Automatic notifications when services recover

## Recovery Validation

### Health Check Procedures

**After Recovery Actions**:
1. **Verify Service Connectivity**
   ```bash
   # Test API endpoints
   curl -f https://api.fogis.com/health
   curl -f https://www.googleapis.com/drive/v3/about
   ```

2. **Run Processing Test**
   ```bash
   # Trigger test processing cycle
   docker-compose exec match-list-processor python -m src.main --test-mode
   ```

3. **Monitor for New Alerts**
   - Wait 10 minutes after recovery
   - Verify no new alerts are generated
   - Check processing logs for errors

### Success Criteria

**Service Recovery Confirmed When**:
- âœ… API endpoints respond successfully
- âœ… Authentication succeeds
- âœ… Processing completes without errors
- âœ… No new alerts generated for 10+ minutes
- âœ… Performance metrics return to normal

## Escalation Procedures

### Level 1: Automated Recovery

**Duration**: 0-15 minutes
**Actions**: Automatic retry mechanisms, graceful degradation
**Notification**: Initial alert sent to operations team

### Level 2: Operations Response

**Duration**: 15-30 minutes
**Actions**: Manual intervention following recovery procedures
**Notification**: Escalation to on-call engineer

### Level 3: Engineering Escalation

**Duration**: 30+ minutes
**Actions**: Code changes, infrastructure modifications
**Notification**: Development team engagement, incident response

### Level 4: External Escalation

**Duration**: 60+ minutes
**Actions**: Contact external service providers
**Notification**: Management notification, customer communication

## Monitoring Dashboard

### Key Metrics

**Service Health**:
- Authentication success rate
- API response times
- Error rates by service
- Alert frequency

**System Performance**:
- Processing cycle times
- Memory and CPU utilization
- Network connectivity status
- Notification delivery rates

### Alert History

**Tracking**:
- Alert frequency trends
- Mean time to resolution
- Recovery success rates
- Escalation patterns

**Reporting**:
- Weekly alert summaries
- Monthly reliability reports
- Quarterly trend analysis
- Annual performance reviews
